@misc{,
title = {{(No Title)}},
url = {https://www.ifad.org/documents/38714170/39135645/smallholders_report.pdf/133e8903-0204-4e7d-a780-bca847933f2e},
urldate = {2021-02-04}
}
@misc{COMPUTERACCESS:1,
AUTHOR="Statista",
title = {{• How many people have access to a computer 2018 | Statista}},
url = {https://www.statista.com/statistics/748551/worldwide-households-with-computer/},
urldate = {2021-02-04},
year = {2021}
}
@misc{Statista:2021,
title = {{• Smartphone users 2020 | Statista}},
url = {https://www.statista.com/statistics/330695/number-of-smartphone-users-worldwide/},
urldate = {2021-02-04},
year = {2021}
}
@inproceedings{Anthonys2009,
abstract = {The classification and recognition of paddy diseases are of the major technical and economical importance in the agricultural industry. To automate these activities, like texture, color and shape, disease recognition system is feasible. The goal of this research is to develop an image recognition system that can recognize paddy diseases. Images were acquired under laboratory condition using digital camera. Three major diseases commonly found in Sri Lanka, Rice blast (Magnaporthe grisea), Rice sheath blight (Rhizoctonia solani) and Brown spot (Cochiobolus miyabeanus] were selected for this research. Image processing starts with the digitized a color image of paddy disease leaf. Then a method of mathematics morphology is used to segment these images. Then texture, shape and color features of color image of disease spot on leaf were extracted, and a classification method of membership function was used to discriminate between the three types of diseases. The analysis of the results showed over 70 percent classification accuracy around 50 sample images. {\textcopyright}2009 IEEE.},
author = {Anthonys, G. and Wickramarachchi, N.},
booktitle = {ICIIS 2009 - 4th International Conference on Industrial and Information Systems 2009, Conference Proceedings},
doi = {10.1109/ICIINFS.2009.5429828},
isbn = {9781424448371},
keywords = {CIE L*a*b* color space,Color texture,Mathematics morphology,Membership function},
pages = {403--407},
title = {{An image recognition system for crop disease identification of paddy fields in Sri Lanka}},
year = {2009}
}
@misc{Globaltt,
title = {{ArabSat 5C - Internet by Satellite in Africa}},
url = {https://www.globaltt.com/en/coverages-Arabsat 5C_C.html},
urldate = {2021-02-04},
year = {2021}
}
@misc{Google,
title = {{best vegetables to grow - Explore - Google Trends}},
url = {https://trends.google.com/trends/explore?q=best vegetables to grow&date=all&geo=US},
urldate = {2021-02-04},
year = {2021}
}
@misc{ImarcGroup,
title = {{Digital Camera Market Share, Size, Trends and Forecast 2021-2026}},
url = {https://www.imarcgroup.com/digital-camera-market},
urldate = {2021-02-04},
year = {2021}
}
@techreport{JLIFADSmallHolders,
author = {Walpole, M., Smith, J., Rosser, A., Brown, C., Schulte-Herbruggen, B., Booth, H., Sassen, M., Mapendembe, A., Fancourt, M., Bieri, M., Glaser, S., Corrigan, C., Narloch, U., Runsten, L., Jenkins, M., Gomera, M. and Hutton, J. },
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Enabling poor rural people to overcome poverty Smallholders, food security, and the environment.pdf:pdf},
title = {{Enabling poor rural people to overcome poverty Smallholders, food security, and the environment}},
url = {https://www.ifad.org/documents/38714170/39135645/smallholders_report.pdf/133e8903-0204-4e7d-a780-bca847933f2e},
year = {2013}
}
@misc{Wikipedia,
title = {{File:Internet users per 100 inhabitants ITU.svg - Wikipedia}},
url = {https://en.wikipedia.org/wiki/File:Internet_users_per_100_inhabitants_ITU.svg},
urldate = {2021-02-04},
year = {2021}
}
@article{Couper2018,
abstract = {Challenges to survey data collection have increased the costs of social research via face-to-face surveys so much that it may become extremely difficult for social scientists to continue using these methods. A key drawback to less expensive Internet-based alternatives is the threat of biased results from coverage errors in survey data. The rise of Internet-enabled smartphones presents an opportunity to re-examine the issue of Internet coverage for surveys and its implications for coverage bias. Two questions (on Internet access and smartphone ownership) were added to the National Survey of Family Growth (NSFG), a U.S. national probability survey of women and men age 15–44, using a continuous sample design. We examine 16 quarters (4 years) of data, from September 2012 to August 2016. Overall, we estimate that 82.9% of the target NSFG population has Internet access, and 81.6% has a smartphone. Combined, this means that about 90.7% of U.S. residents age 15–44 have Internet access, via either traditional devices or a smartphone. We find some evidence of compensatory coverage when looking at key race/ethnicity and age subgroups. For instance, while Black teens (15–18) have the lowest estimated rate of Internet access (81.9%) and the lowest rate of smartphone usage (72.6%), an estimated 88.0% of this subgroup has some form of Internet access. We also examine the socio-demographic correlates of Internet and smartphone coverage, separately and combined, as indicators of technology access in this population. In addition, we look at the effect of differential coverage on key estimates produced by the NSFG, related to fertility, family formation, and sexual activity. While this does not address nonresponse or measurement biases that may differ for alternative modes, our paper has implications for possible coverage biases that may arise when switching to a Web-based mode of data collection, either for follow-up surveys or to replace the main face-to-face data collection.},
author = {Couper, Mick P. and Gremel, Garret and Axinn, William and Guyer, Heidi and Wagner, James and West, Brady T.},
doi = {10.1016/j.ssresearch.2018.03.008},
issn = {0049089X},
journal = {Social Science Research},
keywords = {Coverage bias,Internet,Smartphone,Survey data},
month = {jul},
pages = {221--235},
pmid = {29793688},
publisher = {Academic Press Inc.},
title = {{New options for national population surveys: The implications of internet and smartphone coverage}},
volume = {73},
year = {2018}
}
@article{Affairs2013,
abstract = {The System Usability Scale (SUS) is a reliable tool for measuring the usability.   It consists of a 10 item questionnaire with five response options for respondents; from Strongly agree to Strongly disagree.},
author = {Affairs, Assistant Secretary for Public},
keywords = {UX,User experience,sus,sus questionnaire,system usability scale,usability,usability testing},
month = {sep},
publisher = {Department of Health and Human Services},
title = {{System Usability Scale (SUS)}},
year = {2013}
}
@misc{,
title = {{System Usability Scale (SUS) | Usability.gov}},
url = {https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html},
urldate = {2021-02-04},
year = {2021}
}
@misc{,
title = {{tensorflow/lucid: A collection of infrastructure and tools for research in neural network interpretability.}},
url = {https://github.com/tensorflow/lucid},
urldate = {2021-02-04},
year = {2021}
}
@article{Mohanty2016,
abstract = {Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.},
author = {Mohanty, Sharada P. and Hughes, David P. and Salath{\'{e}}, Marcel},
doi = {10.3389/fpls.2016.01419},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohanty, Hughes, Salath{\'{e}} - 2016 - Using Deep Learning for Image-Based Plant Disease Detection.pdf:pdf},
issn = {1664-462X},
journal = {Frontiers in Plant Science},
keywords = {Crop diseases,Deep learning,Digital epidemiology,Machine learning},
month = {sep},
number = {September},
pages = {1419},
publisher = {Frontiers Research Foundation},
title = {{Using Deep Learning for Image-Based Plant Disease Detection}},
url = {http://journal.frontiersin.org/article/10.3389/fpls.2016.01419/full},
volume = {7},
year = {2016}
}
@misc{System_Usability2020,
title = {{System Usability Scale (SUS) | Usability.gov}},
url = {https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html},
urldate = {2021-02-04},
year = {2021}
}
@techreport{Krizhevsky,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - Unknown - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://code.google.com/p/cuda-convnet/},
year = {2012}
}
@InProceedings{Szegedy_2015_CVPR,
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
title = {Going Deeper With Convolutions},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2015}
}
@misc{Yandex,
url = {https://yandex.com/images/},
year = {2021}
}
