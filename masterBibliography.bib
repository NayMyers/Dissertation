@article{Mohanty2016,
abstract = {Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.},
author = {Mohanty, Sharada P. and Hughes, David P. and Salath{\'{e}}, Marcel},
doi = {10.3389/fpls.2016.01419},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohanty, Hughes, Salath{\'{e}} - 2016 - Using Deep Learning for Image-Based Plant Disease Detection(3).pdf:pdf},
issn = {1664-462X},
journal = {Frontiers in Plant Science},
keywords = {Crop diseases,Deep learning,Digital epidemiology,Machine learning},
month = {sep},
number = {September},
pages = {1419},
publisher = {Frontiers Research Foundation},
title = {{Using Deep Learning for Image-Based Plant Disease Detection}},
url = {http://journal.frontiersin.org/article/10.3389/fpls.2016.01419/full},
volume = {7},
year = {2016}
}
@inproceedings{Khirade2015,
abstract = {Identification of the plant diseases is the key to preventing the losses in the yield and quantity of the agricultural product. The studies of the plant diseases mean the studies of visually observable patterns seen on the plant. Health monitoring and disease detection on plant is very critical for sustainable agriculture. It is very difficult to monitor the plant diseases manually. It requires tremendous amount of work, expertize in the plant diseases, and also require the excessive processing time. Hence, image processing is used for the detection of plant diseases. Disease detection involves the steps like image acquisition, image pre-processing, image segmentation, feature extraction and classification. This paper discussed the methods used for the detection of plant diseases using their leaves images. This paper also discussed some segmentation and feature extraction algorithm used in the plant disease detection.},
author = {Khirade, Sachin D. and Patil, A. B.},
booktitle = {Proceedings - 1st International Conference on Computing, Communication, Control and Automation, ICCUBEA 2015},
doi = {10.1109/ICCUBEA.2015.153},
isbn = {9781479968923},
keywords = {Feature extraction,Image acquisition,Segmentation},
month = {jul},
pages = {768--771},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Plant disease detection using image processing}},
year = {2015}
}
@article{Ashqar2018,
author = {Ashqar, Belal A . M. and Abu-Naser, Samy S.},
keywords = {Article,Deep Learning,Detection,Diseases,Tomato Leaves},
publisher = {IJARW},
title = {{Image-Based Tomato Leaves Diseases Detection Using Deep Learning}},
url = {http://dspace.alazhar.edu.ps/xmlui/handle/123456789/278},
year = {2018}
}
@article{Mohanty2016a,
abstract = {Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.},
author = {Mohanty, Sharada P. and Hughes, David P. and Salath{\'{e}}, Marcel},
doi = {10.3389/fpls.2016.01419},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohanty, Hughes, Salath{\'{e}} - 2016 - Using Deep Learning for Image-Based Plant Disease Detection(2).pdf:pdf},
issn = {1664-462X},
journal = {Frontiers in Plant Science},
keywords = {Crop diseases,Deep learning,Digital epidemiology,Machine learning},
month = {sep},
number = {September},
pages = {1419},
publisher = {Frontiers Research Foundation},
title = {{Using Deep Learning for Image-Based Plant Disease Detection}},
url = {http://journal.frontiersin.org/article/10.3389/fpls.2016.01419/full},
volume = {7},
year = {2016}
}
@inproceedings{Kulkarni2018,
abstract = {In recent times, drastic climate changes and lack of immunity in crops has caused substantial increase in growth of crop diseases. This causes large scale demolition of crops, decreases cultivation and eventually leads to financial loss of farmers. Due to rapid growth in variety of diseases and adequate knowledge of farmer, identification and treatment of the disease has become a major challenge. The leaves have texture and visual similarities which attributes for identification of disease type. Hence, computer vision employed with deep learning provides the way to solve this problem. This paper proposes a deep learning-based model which is trained using public dataset containing images of healthy and diseased crop leaves. The model serves its objective by classifying images of leaves into diseased category based on the pattern of defect.},
author = {Kulkarni, Omkar},
booktitle = {Proceedings - 2018 4th International Conference on Computing, Communication Control and Automation, ICCUBEA 2018},
doi = {10.1109/ICCUBEA.2018.8697390},
isbn = {9781538652572},
keywords = {Crop disease,Deep learning,Image classification,InceptionV3,MobileNet,Transfer Learning},
month = {jul},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Crop Disease Detection Using Deep Learning}},
year = {2018}
}
@techreport{Jaware2012,
abstract = {The K-Means clustering technique is a well-known approach that has been applied to solve low-level image segmentation tasks. This clustering algorithm is convergent and its aim is to optimize the partitioning decisions based on a user-defined initial set of clusters that is updated after each iteration. In the first step we identify the mostly green colored pixels. Next, these pixels are masked based on specific threshold values that are computed using Otsu's method, then those mostly green pixels are masked. The other additional step is that the pixels with zeros red, green and blue values and the pixels on the boundaries of the infected cluster (object) were completely removed. The experimental results demonstrate that the proposed technique is a robust technique for the detection of plant leaves diseases.},
author = {Jaware, Tushar H and Badgujar, Ravindra D and Patil, G and Prof, Asst},
booktitle = {World Journal of Science and Technology},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jaware et al. - 2012 - Held at R.C.Patel Institute of Technology.pdf:pdf},
keywords = {Crop diseases,Image Segmentation,K-Means clustering},
number = {4},
pages = {190--194},
title = {{Held at R.C.Patel Institute of Technology}},
url = {www.worldjournalofscience.com},
volume = {2012},
year = {2012}
}
@techreport{Szegedy2015,
abstract = {We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the Im-ageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC14). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular in-carnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Szegedy et al. - 2015 - Going Deeper with Convolutions.pdf:pdf},
pages = {1--9},
title = {{Going Deeper with Convolutions}},
year = {2015}
}
@techreport{Krizhevsky,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called "dropout" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Krizhevsky, Sutskever, Hinton - Unknown - ImageNet Classification with Deep Convolutional Neural Networks.pdf:pdf},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://code.google.com/p/cuda-convnet/}
}
@misc{,
title = {{best vegetables to grow - Explore - Google Trends}},
url = {https://trends.google.com/trends/explore?q=best vegetables to grow&date=all&geo=US},
urldate = {2021-02-04}
}
@misc{,
title = {{tensorflow/lucid: A collection of infrastructure and tools for research in neural network interpretability.}},
url = {https://github.com/tensorflow/lucid},
urldate = {2021-02-04}
}
@article{Mohanty2016,
abstract = {Crop diseases are a major threat to food security, but their rapid identification remains difficult in many parts of the world due to the lack of the necessary infrastructure. The combination of increasing global smartphone penetration and recent advances in computer vision made possible by deep learning has paved the way for smartphone-assisted disease diagnosis. Using a public dataset of 54,306 images of diseased and healthy plant leaves collected under controlled conditions, we train a deep convolutional neural network to identify 14 crop species and 26 diseases (or absence thereof). The trained model achieves an accuracy of 99.35% on a held-out test set, demonstrating the feasibility of this approach. Overall, the approach of training deep learning models on increasingly large and publicly available image datasets presents a clear path toward smartphone-assisted crop disease diagnosis on a massive global scale.},
author = {Mohanty, Sharada P. and Hughes, David P. and Salath{\'{e}}, Marcel},
doi = {10.3389/fpls.2016.01419},
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohanty, Hughes, Salath{\'{e}} - 2016 - Using Deep Learning for Image-Based Plant Disease Detection.pdf:pdf},
issn = {1664-462X},
journal = {Frontiers in Plant Science},
keywords = {Crop diseases,Deep learning,Digital epidemiology,Machine learning},
month = {sep},
number = {September},
pages = {1419},
publisher = {Frontiers Research Foundation},
title = {{Using Deep Learning for Image-Based Plant Disease Detection}},
url = {http://journal.frontiersin.org/article/10.3389/fpls.2016.01419/full},
volume = {7},
year = {2016}
}
@misc{,
title = {{System Usability Scale (SUS) | Usability.gov}},
url = {https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html},
urldate = {2021-02-04}
}
@misc{,
title = {{(No Title)}},
url = {https://www.ifad.org/documents/38714170/39135645/smallholders_report.pdf/133e8903-0204-4e7d-a780-bca847933f2e},
urldate = {2021-02-04}
}
@misc{,
title = {{ArabSat 5C - Internet by Satellite in Africa}},
url = {https://www.globaltt.com/en/coverages-Arabsat 5C_C.html},
urldate = {2021-02-04}
}
@misc{,
title = {{IEEE Xplore Full-Text PDF:}},
url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8697390},
urldate = {2021-02-07}
}
@misc{,
title = {{Digital Camera Market Share, Size, Trends and Forecast 2021-2026}},
url = {https://www.imarcgroup.com/digital-camera-market},
urldate = {2021-02-04}
}
@article{Affairs2013,
abstract = {The System Usability Scale (SUS) is a reliable tool for measuring the usability.   It consists of a 10 item questionnaire with five response options for respondents; from Strongly agree to Strongly disagree.},
author = {Affairs, Assistant Secretary for Public},
keywords = {UX,User experience,sus,sus questionnaire,system usability scale,usability,usability testing},
month = {sep},
publisher = {Department of Health and Human Services},
title = {{System Usability Scale (SUS)}},
year = {2013}
}
@misc{,
title = {{File:Internet users per 100 inhabitants ITU.svg - Wikipedia}},
url = {https://en.wikipedia.org/wiki/File:Internet_users_per_100_inhabitants_ITU.svg},
urldate = {2021-02-04}
}
@misc{,
title = {{IEEE Xplore Full-Text PDF:}},
url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8697390},
urldate = {2021-02-26}
}
@misc{,
title = {{• Smartphone users 2020 | Statista}},
url = {https://www.statista.com/statistics/330695/number-of-smartphone-users-worldwide/},
urldate = {2021-02-04}
}
@inproceedings{Anthonys2009,
abstract = {The classification and recognition of paddy diseases are of the major technical and economical importance in the agricultural industry. To automate these activities, like texture, color and shape, disease recognition system is feasible. The goal of this research is to develop an image recognition system that can recognize paddy diseases. Images were acquired under laboratory condition using digital camera. Three major diseases commonly found in Sri Lanka, Rice blast (Magnaporthe grisea), Rice sheath blight (Rhizoctonia solani) and Brown spot (Cochiobolus miyabeanus] were selected for this research. Image processing starts with the digitized a color image of paddy disease leaf. Then a method of mathematics morphology is used to segment these images. Then texture, shape and color features of color image of disease spot on leaf were extracted, and a classification method of membership function was used to discriminate between the three types of diseases. The analysis of the results showed over 70 percent classification accuracy around 50 sample images. {\textcopyright}2009 IEEE.},
author = {Anthonys, G. and Wickramarachchi, N.},
booktitle = {ICIIS 2009 - 4th International Conference on Industrial and Information Systems 2009, Conference Proceedings},
doi = {10.1109/ICIINFS.2009.5429828},
isbn = {9781424448371},
keywords = {CIE L*a*b* color space,Color texture,Mathematics morphology,Membership function},
pages = {403--407},
title = {{An image recognition system for crop disease identification of paddy fields in Sri Lanka}},
year = {2009}
}
@techreport{,
file = {:C\:/Users/Ryan-Syme/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2013 - Enabling poor rural people to overcome poverty Smallholders, food security, and the environment.pdf:pdf},
title = {{Enabling poor rural people to overcome poverty Smallholders, food security, and the environment}},
year = {2013}
}
@article{Couper2018,
abstract = {Challenges to survey data collection have increased the costs of social research via face-to-face surveys so much that it may become extremely difficult for social scientists to continue using these methods. A key drawback to less expensive Internet-based alternatives is the threat of biased results from coverage errors in survey data. The rise of Internet-enabled smartphones presents an opportunity to re-examine the issue of Internet coverage for surveys and its implications for coverage bias. Two questions (on Internet access and smartphone ownership) were added to the National Survey of Family Growth (NSFG), a U.S. national probability survey of women and men age 15–44, using a continuous sample design. We examine 16 quarters (4 years) of data, from September 2012 to August 2016. Overall, we estimate that 82.9% of the target NSFG population has Internet access, and 81.6% has a smartphone. Combined, this means that about 90.7% of U.S. residents age 15–44 have Internet access, via either traditional devices or a smartphone. We find some evidence of compensatory coverage when looking at key race/ethnicity and age subgroups. For instance, while Black teens (15–18) have the lowest estimated rate of Internet access (81.9%) and the lowest rate of smartphone usage (72.6%), an estimated 88.0% of this subgroup has some form of Internet access. We also examine the socio-demographic correlates of Internet and smartphone coverage, separately and combined, as indicators of technology access in this population. In addition, we look at the effect of differential coverage on key estimates produced by the NSFG, related to fertility, family formation, and sexual activity. While this does not address nonresponse or measurement biases that may differ for alternative modes, our paper has implications for possible coverage biases that may arise when switching to a Web-based mode of data collection, either for follow-up surveys or to replace the main face-to-face data collection.},
author = {Couper, Mick P. and Gremel, Garret and Axinn, William and Guyer, Heidi and Wagner, James and West, Brady T.},
doi = {10.1016/j.ssresearch.2018.03.008},
issn = {0049089X},
journal = {Social Science Research},
keywords = {Coverage bias,Internet,Smartphone,Survey data},
month = {jul},
pages = {221--235},
pmid = {29793688},
publisher = {Academic Press Inc.},
title = {{New options for national population surveys: The implications of internet and smartphone coverage}},
volume = {73},
year = {2018}
}
@misc{,
title = {{• How many people have access to a computer 2018 | Statista}},
url = {https://www.statista.com/statistics/748551/worldwide-households-with-computer/},
urldate = {2021-02-04}
}
